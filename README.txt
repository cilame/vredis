# 为了有别于工作中所使用的分布式脚本
# 想尝试开发一个个人使用的更加便于开发者使用的分布式代码
# 希望能够从 “对开发者更加友好” 的角度开始从零开始开发一个自己的分布式的爬虫
# 基于 scrapy 以及 redis 并且将有别于工作中使用特殊脚本传递形式来实现的方法进行区分
# 最主要的目的就是让开发者能像是在本机调试一样去调试分布式
# 仅仅像是开发单机的 scrapy 爬虫脚本一样非常快就能直接使用线上的开源分布式架构

# 首先，创建这个库的目标是希望将 scrapy crawl 本地爬虫与分布式爬虫进行接口统一
# 让本地爬虫开启的代码，只需修改一个字母即可实现分布式爬取
# 一般本机 scrapy：
    # 使用本机 scrapy 爬虫
    scrapy crawl spidertest

# 目标分布式爬虫接口实现：
    # 使用分布式 scrapy 爬虫
    vscrapy crawl spidertest
    # 检查所有爬虫状态，分布式特有的一些功能
    vscrapy -l
    # 其他功能想到就添加进去
    ...

并且在部署上做到尽可能的简单。
部署和实现一体化。

# 需求预装环境
scrapy # 基础包
redis # 基于 redis 进行数据传输，所以肯定需要 redis，各种数据配置也需要在这里实现
# 开发过程中可能会参照部分 scrapy-redis 的细节进行优化补充

# 最重要的两点
# 1 debug 要更加方便，特别是能够传输远端爬虫队列里面的错误日志。
# 2 一次部署后续将无需更新。


@20181128
先考虑信号安全传递的方法:
    现在先考虑实现信号的注册，维持和丢失的情况。 
    # 因为想要在 debug 的状态中实现，如果断开调度器时，任务自动停止。便于调试。
    # 后续需要通过类地址来获取类里面的方法字符串
    # 暂时考虑通过 class 来获取 class代码 的方式可以参考 inspect 里面的 getsource 方法。

@20181129
新的想法是想试试去除 master 这个主控，让部署实现变得更加简单一些。

@20181130
后面是考虑到如果需要全局爬虫更好的调度控制可能就需要 master 。但是感觉暂时没有特别的需要。
所以目前考虑的是实现 sender 和 worker 的调配就好了。 master 端可以延后再实现。
    # 今天的难点主要是发生在怎么处理爬虫状态上面
    # 是否开启 debug 状态也是很需要考虑的
    # 保持连接的状态来接收 log。

    # 1，考虑处理状态（开启、执行、关闭）转移的时机，考虑存储状态的结构。
    # 2，考虑怎么在正常状态处理中实现保持连接以及断开连接的信号发送。