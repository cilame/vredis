# 为了有别于工作中所使用的分布式脚本
# 想尝试开发一个个人使用的更加便于开发者使用的分布式代码
# 希望能够从 “对开发者更加友好” 的角度开始从零开始开发一个自己的分布式的爬虫
# 基于 scrapy 以及 redis 并且将有别于工作中使用特殊脚本传递形式来实现的方法进行区分
# 最主要的目的就是让开发者能像是在本机调试一样去调试分布式
# 仅仅像是开发单机的 scrapy 爬虫脚本一样非常快就能直接使用线上的开源分布式架构

# 首先，创建这个库的目标是希望将 scrapy crawl 本地爬虫与分布式爬虫进行接口统一
# 让本地爬虫开启的代码，只需修改一个字母即可实现分布式爬取
# 一般本机 scrapy：
    # 使用本机 scrapy 爬虫
    scrapy crawl spidertest

# 目标分布式爬虫接口实现：
    # 使用分布式 scrapy 爬虫
    vscrapy crawl spidertest
    # 检查所有爬虫状态，分布式特有的一些功能
    vscrapy -l
    # 其他功能想到就添加进去
    ...

并且在部署上做到尽可能的简单。
部署和实现一体化。

# 需求预装环境
# scrapy # 基础包目前的开发暂时没有需要
redis # 基于 redis 进行数据传输，所以肯定需要 redis，各种数据配置也需要在这里实现
# 开发过程中可能会参照部分 scrapy-redis 的细节进行优化补充

# 最重要去实现的两点
# 1 debug 要更加方便，
    [1]特别是能够传输远端爬虫队列里面的错误日志。（ DEBUG 开启状态）
    [2]发送任务端以任意方式断链执行就停止。（相同的任务才会停止）
        即，不同的发送端口每次发送时的任务id肯定不一样，一个发送端绑定一个任务 id
        该发送端任意方式断开连接则该任务 id 执行结束，不影响其他任务 id
# 2 一次部署后续将无需更新。

@20181128
先考虑信号安全传递的方法:
    现在先考虑实现信号的注册，维持和丢失的情况。 
    # 因为想要在 debug 的状态中实现，如果断开调度器时，任务自动停止。便于调试。
    # 后续需要通过类地址来获取类里面的方法字符串
    # 暂时考虑通过 class 来获取 class代码 的方式可以参考 inspect 里面的 getsource 方法。

@20181129
原本是有 master worker sender 来代表主控部，工作部，任务发送部
现在去除 master 这个主控，让部署实现变得更加简单一些。让工作端只需要知道 redis 的地址和密码即可。

@20181130
后面是考虑到如果需要全局爬虫更好的调度控制可能就需要 master 。但是感觉暂时没有特别的需要。
所以目前考虑的是实现 sender 和 worker 的调配就好了。 master 端可以延后再实现。
    # 今天的难点主要是发生在怎么处理爬虫状态上面
    # 是否开启 debug 状态也是很需要考虑的
    # 保持连接的状态来接收 log。

    # 1，考虑处理状态（开启、执行、关闭）转移的时机，考虑存储状态的结构。
    # 2，考虑怎么在正常状态处理中实现保持连接以及断开连接的信号发送。

@20181203
以上功能基本已经实现简单的雏形，不过维护任务广播的心跳功能可能会稍微有点不太合理
因为维护只需要一个信号就行，但是这里的实现是去中心处理的只有 worker 端的处理
所以目前在运行量比较少的情况下，暂时就使用每个 worker 60秒心跳广播一次来维护广播存活
    # 今天的难点可能就主要是了解一些 twisted 的框架，看看怎么处理会更好的结合
    # 目前用的是开启线程的方式来将新到的任务丢入线程去执行的（但执行端用线程可能效率低）
    # 考虑到后续 scrapy 爬虫功能的扩展，这里还需要对 scrapy 的执行要去了解。
    # 最后再根据需求将日志的格式整理得更好一些

@20181204
发现之前需要心跳的处理有误，原因是这边的一个设定失误才会超时停止，现在已经去除心跳线程
代码比之前更简洁了一些，现在需要将这边的接口弄得更像接口一点，还有虫子本身的日志处理
    # 日志处理可以考虑根据 workerid 来存放在结构里面。日志检查的接口也要并行开发处理，便于检查。
    # 目前就需要整理一下接口的处理，让函数实现更方便一些，twisted 的学习可能需要放在后面一些时间
    # 两个大问题
    # 1 如何记录日志
    # 2 如何执行任务
    # 功能角度上要先实现查询所有存活 worker 的功能
    # 通过挂钩标准输出的函数可以实现 worker 所有输出都传递到这边
    # 增加更多通过 sender 进行动态配置参数的接口

@20181205
可能需要在输出的时候再加上一层 taskid 的封装，今天考虑将日志回显标准化。
由于挂钩点唯一性 stdout 和 stderr。不方便针对任务进行挂钩。怎么增加一个选择的标识呢？
目前的想法就是通过 inspect.stack 来实现查找当前 taskid 来通过 taskid 进行传递
    # 目前已通过 inspect.stack 实现该功能
    # 不过就是传递方面可能还需要将之前的耦合性比较强的代码再整理一下
