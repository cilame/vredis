# 为了有别于工作中所使用的分布式脚本
# 想尝试开发一个个人使用的更加便于开发者使用的分布式代码
# 希望能够从 “对开发者更加友好” 的角度开始从零开始开发一个自己的分布式的爬虫
# 基于 scrapy 以及 redis 并且将有别于工作中使用特殊脚本传递形式来实现的方法进行区分
# 最主要的目的就是让开发者能像是在本机调试一样去调试分布式
# 仅仅像是开发单机的 scrapy 爬虫脚本一样非常快就能直接使用线上的开源分布式架构

# 首先，创建这个库的目标是希望将 scrapy crawl 本地爬虫与分布式爬虫进行接口统一
# 让本地爬虫开启的代码，只需修改一个字母即可实现分布式爬取
# 一般本机 scrapy：
    # 使用本机 scrapy 爬虫
    scrapy crawl spidertest

# 目标分布式爬虫接口实现：
    # 使用分布式 scrapy 爬虫
    vscrapy crawl spidertest
    # 检查所有爬虫状态，分布式特有的一些功能
    vscrapy -l
    # 连接这些任务的实时输出状态
    vscrapy -c --connect 123,333,345 
    # 其他功能想到就添加进去
    ...

并且在部署上做到尽可能的简单。
部署和实现一体化。

# 需求预装环境
# scrapy # 基础包目前的开发暂时没有需要
redis # 基于 redis 进行数据传输，所以肯定需要 redis，各种数据配置也需要在这里实现
# 开发过程中可能会参照部分 scrapy-redis 的细节进行优化补充

# 最重要去实现的两点
# 1 debug 要更加方便，
    [1]特别是能够传输远端爬虫队列里面的错误日志。（ DEBUG 开启状态）
    [2]发送任务端以任意方式断链执行就停止。（相同的任务才会停止）
        即，不同的发送端口每次发送时的任务id肯定不一样，一个发送端绑定一个任务 id
        该发送端任意方式断开连接则该任务 id 执行结束，不影响其他任务 id
# 2 一次部署后续将无需更新。

@20181128
先考虑信号安全传递的方法:
    现在先考虑实现信号的注册，维持和丢失的情况。 
    # 因为想要在 debug 的状态中实现，如果断开调度器时，任务自动停止。便于调试。
    # 后续需要通过类地址来获取类里面的方法字符串
    # 暂时考虑通过 class 来获取 class代码 的方式可以参考 inspect 里面的 getsource 方法。

@20181129
原本是有 master worker sender 来代表主控部，工作部，任务发送部
现在去除 master 这个主控，让部署实现变得更加简单一些。让工作端只需要知道 redis 的地址和密码即可。

@20181130
后面是考虑到如果需要全局爬虫更好的调度控制可能就需要 master 。但是感觉暂时没有特别的需要。
所以目前考虑的是实现 sender 和 worker 的调配就好了。 master 端可以延后再实现。
    # 今天的难点主要是发生在怎么处理爬虫状态上面
    # 是否开启 debug 状态也是很需要考虑的
    # 保持连接的状态来接收 log。

    # 1，考虑处理状态（开启、执行、关闭）转移的时机，考虑存储状态的结构。
    # 2，考虑怎么在正常状态处理中实现保持连接以及断开连接的信号发送。

@20181203
以上功能基本已经实现简单的雏形，不过维护任务广播的心跳功能可能会稍微有点不太合理
因为维护只需要一个信号就行，但是这里的实现是去中心处理的只有 worker 端的处理
所以目前在运行量比较少的情况下，暂时就使用每个 worker 60秒心跳广播一次来维护广播存活
    # 今天的难点可能就主要是了解一些 twisted 的框架，看看怎么处理会更好的结合
    # 目前用的是开启线程的方式来将新到的任务丢入线程去执行的（但执行端用线程可能效率低）
    # 考虑到后续 scrapy 爬虫功能的扩展，这里还需要对 scrapy 的执行要去了解。
    # 最后再根据需求将日志的格式整理得更好一些

@20181204
发现之前需要心跳的处理有误，原因是这边的一个设定失误才会超时停止，现在已经去除心跳线程
代码比之前更简洁了一些，现在需要将这边的接口弄得更像接口一点，还有虫子本身的日志处理
    # 日志处理可以考虑根据 workerid 来存放在结构里面。日志检查的接口也要并行开发处理，便于检查。
    # 目前就需要整理一下接口的处理，让函数实现更方便一些，twisted 的学习可能需要放在后面一些时间
    # 两个大问题
    # 1 如何记录日志
    # 2 如何执行任务
    # 功能角度上要先实现查询所有存活 worker 的功能
    # 通过挂钩标准输出的函数可以实现 worker 所有输出都传递到这边
    # 增加更多通过 sender 进行动态配置参数的接口

@20181205
可能需要在输出的时候再加上一层 taskid 的封装，今天考虑将日志回显标准化。
由于挂钩点唯一性 stdout 和 stderr。不方便针对任务进行挂钩。怎么增加一个选择的标识呢？
目前的想法就是通过 inspect.stack 来实现查找当前 taskid 来通过 taskid 进行传递
    # 目前已通过 inspect.stack 实现该功能
    # 不过就是传递方面可能还需要将之前的耦合性比较强的代码再整理一下
    # 后续将完整实现，能够根据 taskid 和 workerid 来监听某个任务下-
    # 某个 worker 的实时输出状态。并且后续还需扩展日志持久化处理。
    # 也就是说传一个函数脚本过去，worker 执行时不管你在里面用什么输出，都可以捕捉
    # 或是 print 或是 logging 的内容都可以回传到发送端。能捕捉的问题解决基本就OK
    # 剩下就是实现简单回传功能
    # （需要考虑根据开关实现，可能需要抽象一个 Flag 类来存放）
    # （可能挂钩函数还需要更多地与 Flag 类相关，还需要更多魔改）
    # 目前检擦实时连接状态还没有被更好的解耦。可能需要魔改迭代器？
    # 还是说因为传过去的脚本本身就是字符串，可以用正则进行插入字符串再解析？
    # 1，完善实时回传功能
    # 2，完善 Flag 类作为开关的功能
    # 3，考虑实时检测 sender 连接状态的解耦
    #     期望是在 DEBUG 状态下 sender 端断开就任务就停止，避免资源浪费

#20181206
将对应于之前的 Flag 类的想法，这边将那个想法改名为 Valve（阀门）。
将会生成一个全局的阀门实例，让所有通过阀门的任务都需要在传送过来的配置下来进行传输的控制。
eg。 在传输端将一个 DEBUG 配置传输过来，这边会根据配置将使用 DEBUG 模式来实现管道的传输。
    能够在后续指定需要哪个任务需要回传，需要哪些更多配置的操作，这样就会方便很多。
    # DEBUG：后续增加一个 workerid 查重的功能，因为可能有人指定 workerid 后续若重复存在会有问题。
    # 检查状态需要考虑
    # 后面可能需要试试考虑学一点py解释器的内容，目的是想挂钩全局的迭代工作。（或许不太可能实现）
    # 现在主要的任务：
    # 实现简单的 task 配置隔离和简单的回传显示
    # 由于想要实现这些又可能会与传送任务的指令结构有相关性，所以设计指令规范迫在眉睫。

#20181207
先考虑规范化回传的内容，确认回传的一些默认配置，先使用 logging 库覆盖现在不是很规范的 print
然后发现 logging 有很多坑，就先将就现在的状况就好，print 其实也挺好用的。
    # 简单的回写已经做好，不过，每一个都需要回写，传入管道之后这边通过过滤前缀的方式来拿出一个 worker 的回写 print
    # 不过暂时是没有支持动态的修改目标机器的 DEBUG 状态来关闭回写，这边需要考虑这类的配置，不过在功能上可能会
    # 不能挂钩比较复杂的 console 输出处理稍微有点可惜，后续有必要再考虑。print 已经非常够用了。
    # 有四个任务功能需要实现。
    # 0 检查任务
    # 1 配置任务。
    # 2 获取数据任务。（用redis就是看中这分布式共享管道功能）
    # 3 分发任务。（这里需要非常小心的考虑怎么处理脚本的传输）
    #     一般需要执行复杂任务的，这里需要添加命令行执行任务的操作
    
#20181208
作为传输的结构，暂时先考虑使用 {'command': <str> ,'subcommand': <dict> ,'settings': <dict> }
暂时都使用 print 回传的方式来进行数据回传，可以在阀门这个类上下功夫应该就能解决，不过
今天杭州下雪，太TM冷了，今天后面的时间都休息，明天再搞。
    # 吃完饭满血复活，晚上继续搞起。
    # 后续可能需要考虑在执行之前进行 worker 端口的存活验证，主要是如果在配置随机选一个端进行会写检查的话
    # 需要在发送任务之前事先知道那些任务端还活着。后续如果需要配置使用哪一个 worker 端的话，
    # 也需要事先知道那些任务端还活着。考虑通过一个隐藏任务，即不消费任务号码的任务进行特殊处理。

#20181209
现在突然发现一个很好的解决默认配置传输的方式，就是在对指令结构预检查的时候进行补充和配置，
这个很好解决了不同的指令存在相互交叉的默认配置，这样也能更好的调配工作。我觉得OK。
    # 任务的模型也越来越符合我心目中的标准了。不过还是对后期可能需要并入 twisted 表示有一定的担心
    # 因为目前是完全基于 threading 线程库进行的开发，所以后期要是改 twisted 可能需要很长时间。
    # 毕竟 twisted 的文档有点让人难受的。
    # 不过事实上目前的功能也可以在一定程度上分成一个单独的功能库出去。改成接口的形式来实现？